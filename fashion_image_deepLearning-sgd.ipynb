{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "from glob import glob\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hi\\Desktop\\DeepLearning\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hi\\Desktop\\DeepLearning\\img-fashion\n"
     ]
    }
   ],
   "source": [
    "base_dir = os.chdir(os.getcwd() + \"/img-fashion\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 개수 >>  7652\n",
      "파일 목록 타입 >>  <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "data_list = glob('*.jpg')\n",
    "print('파일 개수 >> ', len(data_list))\n",
    "print('파일 목록 타입 >> ', type(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blouse', '1', 'jpg']\n"
     ]
    }
   ],
   "source": [
    "token = text_to_word_sequence(data_list[0])\n",
    "print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7652\n"
     ]
    }
   ],
   "source": [
    "label = []\n",
    "for x in data_list:\n",
    "    token = text_to_word_sequence(x)\n",
    "    label.append(token[0])\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 7, 7, 7], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = label\n",
    "encoder = LabelEncoder()\n",
    "label = encoder.fit_transform(items)\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_height = 150\n",
    "data_width = 150\n",
    "channel_n = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_file(dat_height, data_width, channel_n, data_list_len):\n",
    "    label = []\n",
    "    images = np.zeros((data_list_len, dat_height, data_width, channel_n))\n",
    "    \n",
    "    for i, image in enumerate(data_list):\n",
    "        \n",
    "        token = text_to_word_sequence(image)\n",
    "        label.append(token[0])\n",
    "        \n",
    "        image = cv2.imread(image)\n",
    "        image = cv2.resize(image, (dat_height, data_width)) / 255\n",
    "        \n",
    "        images[i, :, :, :] = image\n",
    "    label = np.array(label)\n",
    "    return (label, images)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, images = make_file(data_height, data_width, channel_n, len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 7, 7, 7], dtype=int64), 7652)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = label\n",
    "encoder = LabelEncoder()\n",
    "label = encoder.fit_transform(items)\n",
    "label, len(label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6121, 150, 150, 3) (1531, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "x = images\n",
    "y = label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, \n",
    "                                                    y, \n",
    "                                                    test_size= 0.2,\n",
    "                                                    random_state=30\n",
    "                                                   )\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-14-aa21a617ab3d>\", line 2, in <module>\n",
      "    input_shape=[data_height, data_width, channel_n], classes=8)\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\applications\\__init__.py\", line 46, in wrapper\n",
      "    return base_fun(*args, **kwargs)\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\applications\\resnet.py\", line 33, in ResNet50\n",
      "    return resnet.ResNet50(*args, **kwargs)\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\keras_applications\\resnet_common.py\", line 435, in ResNet50\n",
      "    **kwargs)\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\keras_applications\\resnet_common.py\", line 411, in ResNet\n",
      "    model.load_weights(weights_path)\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 234, in load_weights\n",
      "    return super(Model, self).load_weights(filepath, by_name, skip_mismatch)\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\", line 1222, in load_weights\n",
      "    hdf5_format.load_weights_from_hdf5_group(f, self.layers)\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\saving\\hdf5_format.py\", line 651, in load_weights_from_hdf5_group\n",
      "    original_keras_version = f.attrs['keras_version'].decode('utf8')\n",
      "AttributeError: 'str' object has no attribute 'decode'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'AttributeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\inspect.py\", line 1495, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\inspect.py\", line 1453, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\n",
      "    module = self._load()\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\n",
      "    module = _importlib.import_module(self.__name__)\n",
      "  File \"C:\\Users\\hi\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 965, in _find_and_load_unlocked\n",
      "ModuleNotFoundError: No module named 'tensorflow_core.estimator'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "cnn_base = ResNet50(include_top=False, weights='imagenet',\n",
    "                   input_shape=[data_height, data_width, channel_n], classes=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(cnn_base) \n",
    "model.add(Flatten()) ## 이미지 데이터를 1차원으로 만들어주는 객체 \n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "# model.add(Dropout(rate=0.3))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dropout(rate=0.7))\n",
    "\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "cp = ModelCheckpoint('fashion_cnn_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.0001, decay=1e-6, momentum= 0.9, nesterov = True)\n",
    "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnn_history = model.fit( X_train, \n",
    "                       y_train,                \n",
    "                       batch_size=256,\n",
    "                       epochs=50,\n",
    "                       validation_data = (X_test, y_test),\n",
    "                       callbacks = [es, cp],\n",
    "                       verbose=2\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.evaluate(X_test, y_test)\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test acc: ', round(test_result[1]*100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1) ## 1행2열의 도표, 1열\n",
    "plt.plot(cnn_history.history['accuracy'])\n",
    "plt.plot(cnn_history.history['val_accuracy'])\n",
    "plt.title('model acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend(['train_acc','test_acc'])\n",
    "\n",
    "plt.subplot(1, 2, 2) ## 1행2열의 도표, 2열\n",
    "plt.plot(cnn_history.history['loss'])\n",
    "plt.plot(cnn_history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train_loss','test_loss'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
